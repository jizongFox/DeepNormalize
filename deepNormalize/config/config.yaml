models:
  Generator:
    name: "UNet3D"
    type: "UNet3D"
    params:
      feature_maps: 64
      in_channels: 1
      out_channels: 1
      num_levels: 4
      conv_kernel_size: 3
      pool_kernel_size: 2
      pooling_type: "MaxPool3d"
      num_groups: !!null
      padding: !python/tuple [1, 1, 1, 1, 1, 1]
      activation: "ReLU"
      interpolation: True
      scale_factor: !python/tuple [2, 2, 2] # Used as the multiplier for the image H/W/D in torch.nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation from the corresponding encoder.
    optimizers:
      - type: "FusedSGD"
        params:
          lr: 0.00001
          momentum: 0.9
          weight_decay: 0.001
    schedulers:
      - type: "ReduceLROnPlateau"
        params:
          mode: "min"
          factor: 0.1
          patience: 100
    criterion:
      type: "MSELoss"
      params:
    metrics:
      - type: "Accuracy"
  Segmenter:
    name: "UNet3D"
    type: "UNet3D"
    params:
      feature_maps: 64
      in_channels: 1
      out_channels: 4
      num_levels: 4
      conv_kernel_size: 3
      pool_kernel_size: 2
      pooling_type: "MaxPool3d"
      num_groups: !!null
      padding: !python/tuple [1, 1, 1, 1, 1, 1]
      activation: "ReLU"
      interpolation: True
      scale_factor: !python/tuple [2, 2, 2] # Used as the multiplier for the image H/W/D in torch.nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation from the corresponding encoder.
    optimizers:
      - type: "FusedSGD"
        params:
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.001
    schedulers:
      - type: "ReduceLROnPlateau"
        params:
          mode: "min"
          factor: 0.1
          patience: 3
    criterion:
      type: "DiceLoss"
      params:
        reduction: !!null
        ignore_index: -100
        weight: !torch/tensor [0.22141935, 0.28180645, 0.23845161, 0.25832258]
    metrics:
      - type: "Dice"
        params:
          num_classes: 4
          reduction: !!null
          ignore_index: 0
          average: !!null
          weight: !!null
  Discriminator:
    name: "ResNet3D"
    type: "ResNet18"
    params:
      in_channels: 1
      out_channels: 3
      num_groups: 8
      conv_groups: 1
      width_per_group: 64
      padding: !!null
      activation: "ReLU"
      zero_init_residual: False
      replace_stride_with_dilation: !!null
    optimizers:
      - type: "FusedSGD"
        params:
          lr: 0.0001
          momentum: 0.9
          weight_decay: 0.1
    schedulers:
      - type: "ReduceLROnPlateau"
        params:
          mode: "min"
          factor: 0.1
          patience: 100
    criterion:
      type: "NLLLoss"
      params:
    metrics:
      - type: "Accuracy"

dataset:
  - name: iSEG
    path: "/mnt/md0/Data/Preprocessed/iSEG/Patches/Aligned"
    validation_split: 0.2
    training:
      patch_size: [1, 32, 32, 32]
      step: [1, 8, 8, 8]
    validation:
      patch_size: [1, 32, 32, 32]
      step: [1, 8, 8, 8]
    test:
      patch_size: [1, 32, 32, 32]
      step: [1, 32, 32, 32]
  - name: MRBrainS
    path: "/mnt/md0/Data/Preprocessed/MRBrainS/Patches/Aligned"
    validation_split: 0.2
    training:
      patch_size: [1, 32, 32, 32]
      step: [1, 8, 8, 8]
    validation:
      patch_size: [1, 32, 32, 32]
      step: [1, 8, 8, 8]
    test:
      patch_size: [1, 32, 32, 32]
      step: [1, 32, 32, 32]

training:
  batch_size: 16
  nb_epochs: 50
  patience_segmentation: 3
  variables:
    disc_ratio: 1.0
    seg_ratio: 1.0
    train_generator_every_n_steps: 5
    train_generator_every_n_steps_seg: 1

visdom:
  server: "10.0.3.9"
  port: "8097"
  env: "deepNormalize_test_kerosene_v1.1"

logger:
  path: "/tmp/ml/tests"
  log_after_iterations: 50

